# âš¡ Quick Start Guide

## **YES - Webcam Runs Locally! âœ…**

All code executes **100% locally**. No cloud services. No external APIs. Complete privacy.

---

## ğŸš€ Launch Webcam Tracking (30 Seconds)

```bash
cd /workspaces/GAZE-
streamlit run webcam_ui.py
```

**Then:**
1. Open http://localhost:8502 in your browser
2. Click **"Webcam Tracking"** tab
3. Click **"â–¶ï¸ Start Tracking"** button
4. Watch the red dot - your eyes follow it
5. View real-time gaze trajectory
6. Click **"â¹ï¸ Stop"** when done
7. Click **"ğŸ“Š Analyze Session"** for metrics

---

## ğŸ“Š What You Get

- **Real-time eye tracking** with facial landmarks
- **Eye region crops** showing pupil position
- **Gaze trajectory** visualization
- **ASD-like probability score** (0-100%)
- **Feature metrics**: fixation, saccades, entropy, etc.
- **All processed locally** on your machine

---

## ğŸ§ª Run Examples (2 Minutes)

```bash
python example.py
```

Shows:
1. Face detection from webcam (10 frames)
2. Handcrafted feature extraction
3. Model training on synthetic data
4. End-to-end session analysis

---

## ğŸ¤– Train Custom Model (5 Minutes)

```python
from src.train import DatasetManager, ModelTrainer

# Create dataset
dm = DatasetManager()
df = dm.create_synthetic_dataset(num_td=200, num_asd=200)
train, val, test = dm.split_train_val_test(df)

# Train
trainer = ModelTrainer("random_forest")
trainer.train_random_forest(
    train.drop("label", axis=1).values,
    train["label"].values,
    val.drop("label", axis=1).values,
    val["label"].values,
)

# Evaluate
metrics = trainer.evaluate(test.drop("label", axis=1).values, test["label"].values)
print(f"Accuracy: {metrics['accuracy']:.2%}")
```

---

## ğŸ“‹ Dependencies Status

âœ… PyTorch 2.9.1 (CPU)  
âœ… OpenCV 4.12.0  
âœ… MediaPipe 0.10.31  
âœ… Streamlit 1.53.0  
âœ… scikit-learn  
âœ… pandas, numpy, scipy  

All installed and ready!

---

## ğŸ¯ System Requirements

- **Python**: 3.8+ (you have 3.12+) âœ…
- **RAM**: 2GB+ âœ…
- **Storage**: ~500MB âœ…
- **Webcam**: Optional (for live tracking) âœ…
- **GPU**: Not required (CPU works fine) âœ…

---

## ğŸ”§ Troubleshooting

**"Webcam not detected?"**
â†’ Try demo mode in UI (synthetic data)

**"Module import error?"**
â†’ Run: `pip install -r requirements.txt`

**"Port 8502 already in use?"**
â†’ Run: `streamlit run webcam_ui.py --server.port 8503`

**"Need to train a model?"**
â†’ Example in README.md or run `python example.py`

---

## ğŸ“ File Guide

| File | Purpose |
|------|---------|
| **webcam_ui.py** | Main Streamlit interface â­ START HERE |
| **example.py** | Working examples of all features |
| **config.py** | All settings & hyperparameters |
| **src/preprocessing.py** | Face detection & eye extraction |
| **src/feature_extraction.py** | 17 gaze metrics |
| **src/model.py** | ML models (RF + NN) |
| **src/train.py** | Training pipeline |

---

## âš ï¸ Important Notes

âœ… **Privacy**: Everything runs locally - no data leaves your computer  
âœ… **Research Only**: Not a diagnostic tool - cannot diagnose autism  
âœ… **Educational**: Great for learning gaze tracking & ML  
âœ… **Open Source**: Full code available, modify as needed  

---

## Next Steps

1. **Run Streamlit**: `streamlit run webcam_ui.py`
2. **Explore Demo**: Try the demo mode with synthetic data
3. **Use Your Webcam**: Record your own tracking session
4. **Train a Model**: Follow example.py or README
5. **Review Code**: Check src/ modules for details

---

**Status**: Production-ready | All local | Privacy-first | Full documentation

Good luck! ğŸš€
